# 2024秋超算考核试题 Python试题

## 一、安装虚拟机

### 安装虚拟机及 Ubuntu 22.04 LTS 操作系统
忘了，跟着chatgpt一步步做的，没什么问题出现
### 配置虚拟机网络
如图所示，在windows界面win+R后输入cmd进入终端，然后输入ipconfig查询本地ip地址

将查询到的ipv4地址填入虚拟机网络设置界面即可。

![1](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/1.png)

不过要注意的是火狐并不会直接使用网络代理，得在火狐浏览器里再设置一遍。

所以我毅然将火狐删了换成了谷歌。

## 二、安装Python并配置HPC环境

### 安装 Python 3.x
在虚拟机终端输入以下命令即可——

sudo apt-get update

sudo apt-get install python3

然后，检查版本是否正确，如图所示——

![2](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/2.png)
### 安装相关库
安装pip（Python包管理器）

![3](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/3.png)

如图所示，输入完密码后就会自动安装

然后安装mpi4py 和 multiprocessing

其中multiprocessing是Python标准库的一部分，不需要单独安装

而mpi4y只需输入以下指令即可sudo apt install python3-mpi4py

### 配置Visual Sudio Code
安装vscode后安装python扩展（extensions搜python出来的前两项就是）

![4](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/4.png)

如果vscode使用的环境默认是虚拟机里的话，相关库应该是不需要重复安装

可以直接运行下相关库来检测一下

![5](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/5.png)

当然，在那之前需要在文件管理器中用vscode打开你想使用的文件夹

然后右键新建一个py文件（在命名时加上.py指定文件类型）

![6](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/6.png)

以上，就是环境配置部分。除此之外值得注意的还有（写实验报告中途想起来的）——

虚拟机终端里复制是ctrl+shift+C！

调整vscode字符大小的快捷键是ctrl++

虚拟机的显存尽量调高避免黑屏&花屏

![7](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/7.png)

共享粘贴板设置成双向能方便很多

由于版本问题，挺多用到python的指令需要用python3来代替

**（最重要的）重启能解决非常多问题**


## 三、实现矩阵乘法

### （补充）记录算法优化情况
可想而知，当我们最后端出一个个实现矩阵乘法的方式后会

需要一个或者不止一个可量化的数据去衡量各种方法的优劣

除了常见的time库可以帮助我们记录程序的耗时以外

psutil库可以帮助我们监控内存使用情况和CPU使用率

理想情况是用最少的内存和CPU办最多的事

当然，一般来讲优先考虑的还是耗时

（最后因为cpu使用率的读取没整明白被迫暂时放弃记录这一数据）


### 暴力解法
尝试使用 浙江技术选考生都会用的基础知识 写的矩阵乘法——
```python
import random
import time
time1 = time.time()
def juzheng(n):
    martix = []
    for i in range(n):
        martix.append([random.randint(1,10) for i in range(n)])
    return martix
n = int(input("请输入矩阵的大小："))
A = juzheng(n)
B = juzheng(n)
C = [[0 for i in range(n)] for i in range(n)]
for i in range(n):
    for j in range(n):
        for k in range(n):
            C[i][j] += A[i][k] * B[k][j]
time2 = time.time()
time3 = time2 - time1
print(C)
print(f"矩阵乘法耗时{time3:.6f}秒")
```

试着填入n=1000

*a few minutes later~*

![8](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/main/8.png)

很显然，考虑到本算法的时间复杂度——O(n**3)

试图让它去完成10000*10000的矩阵算法并不现实

于是我们可以尝试开始优化算法

### 初步优化
我们要处理的大矩阵乘法，难点正在这“大”上
```python
import time
time1 = time.time()
n = int(input("请输入矩阵的大小："))
A = [[0 for i in range (n)]for i in range (n)]
time2 = time.time()
print(f"矩阵生成耗时{time2 - time1:.6f}秒")
```
就像这样最简单的生成一个大矩阵，都相当消耗时间

甚至访问一遍矩阵都比生成一个矩阵要久

![9](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/9.png)

于是我们就有了一个思路——拆分，把大矩阵拆成几个部分来处理

例如每次访问，我们都只访问其中一部分——
```python
import random
import time
time1 = time.time()
def juzheng(n):
    martix = []
    for i in range(n):
        martix.append([random.randint(1,10) for i in range(n)])
    return martix
n = int(input("请输入矩阵的大小："))
A = juzheng(n)
B = juzheng(n)
C = [[0 for i in range(n)] for i in range(n)]
#行列转换，预先缓存 B 的列
B_T = list(zip(*B))
for i in range(n):
    A_i = A[i]  #缓存 A[i]，减少重复访问
    for j in range(n):
        B_j = B_T[j]  #缓存 B 的第 j 列，减少重复访问
        sum = 0
        for k in range(n):
            sum += A_i[k] * B_j[k]
        C[i][j] = sum
time2 = time.time()
time3 = time2 - time1
print(f"矩阵乘法耗时{time3:.6f}秒")
```
![10](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/10.png)

快了三分钟不止，但这还只是1000规模的

然后我试了下ai推荐的几个优化方案有的稍快有的稍慢

其中有次跑到了250秒以内，但继续优化之后又回到了600s+（乐）

总的来说，想处理10000*10000规模的矩阵乘法依旧差得远

所以，可以开始我们实验的正题了

### 引入相关库对算法进行优化
先从numpy库开始。我们需要用到的是库中用于数据计算的np部分——
```python
import numpy as np
import time

def matrix_multiply(A, B):
    return np.dot(A, B)

def main():
    # 定义矩阵大小
    N = int(input("矩阵大小："))  # 示例大小，可以调整

    # 生成大矩阵 A 和 B
    A = np.random.rand(N, N)
    B = np.random.rand(N, N)

    # 记录开始时间
    start_time = time.time()

    # 执行矩阵乘法
    C = matrix_multiply(A, B)

    # 记录结束时间
    end_time = time.time()

    # 计算耗时
    elapsed_time = end_time - start_time

    print(f"矩阵乘法耗时{elapsed_time:.6f}秒")

if __name__ == "__main__":
    main()
```
提一嘴运行函数的判定语句——if __name__ == "__main__":

__name__是读取当前程序的名称，如果是"__main__"的话说明当前的程序即定义函数本身的程序

这样做可以避免当别的程序调用这个函数时进行不必要的运行

（尽管本次实验中规模较小，无需将函数单独建立文件反复调用）

耗时0.874166秒

秒了！

(不过这里有一点不严谨的是前后数值大小范围的设置不一样，但实际上影响基本没有)

至于为什么导入numpy库后能快这么多，去问ai吧（

我的理解是这个库基于更底层的代码编写，能更好地针对性优化线性代数相关计算

于是就把所有矩阵计算相关的都丢给np就好

例如生成矩阵（np.random.rand）、矩阵乘法（np.dot）以及后面的矩阵分块（np.array_split）和验算（np.array_split）

（多次因为忘记了用np来进行矩阵分块导致计算速度缓慢（悲））

正所谓工欲善其事 必先利其器

然后我们总算可以大胆尝试10000*10000规模的矩阵乘法了

![12](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/12.png)

是能完成了，但还是太慢，至少我不愿意再花这么长时间等待结果了（

那就再来一个库吧——
```python
from mpi4py import MPI
import time
import numpy as np

def matrix_multiply(A, B):
    return np.dot(A, B)

def main():
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    if rank == 0:
        #输入矩阵大小
        N = int(input("请输入矩阵大小："))
    else:
        N = None

    #广播矩阵大小给所有进程
    N = comm.bcast(N, root=0)

    if rank == 0:
        #生成大矩阵 A 和 B
        A = np.random.rand(N, N)
        B = np.random.rand(N, N)
        
        #将矩阵 A 分块
        chunks = np.array_split(A, size, axis=0)
    else:
        A = None
        B = None
        chunks = None

    #将 A 的块分发给所有进程
    local_A = comm.scatter(chunks, root=0)

    #将矩阵 B 广播给所有进程
    B = comm.bcast(B, root=0)

    #记录开始时间
    start_time = time.time()

    #执行局部矩阵乘法
    local_C = matrix_multiply(local_A, B)

    #将局部结果收集到最终矩阵 C 中
    C = comm.gather(local_C, root=0)

    #记录结束时间
    end_time = time.time()

    if rank == 0:
        #合并结果
        C = np.vstack(C)
        elapsed_time = end_time - start_time
        print(f"矩阵乘法耗时{elapsed_time:.6f}秒")

if __name__ == "__main__":
    main()
```
mpi4py这个库实现的则是多进程计算同一个问题，依旧是前面提过的拆分想法

而mpi4y的启动是由MPI启动器来启动或管理的

所以运行它的代码会是mpiexec -n 4 python3 程序名.py 

其中4是进程数，可以按需求更改成别的数

效果可谓是显著

不过也能看到，让进程去通信也是需要额外成本的

这也好理解，现实中多个人去做同一件事也是要产生额外沟通成本的

同时为了方便，可以将程序设置成能连续执行多次（我怎么现在才想到）代码如下——
```python
from mpi4py import MPI
import time
import numpy as np

def main():
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    if rank == 0:
        # 输入矩阵大小和执行次数
        N = int(input("请输入矩阵大小："))
        num_executions = int(input("请输入执行次数："))
    else:
        N = None
        num_executions = None

    # 广播矩阵大小和执行次数给所有进程
    N = comm.bcast(N, root=0)
    num_executions = comm.bcast(num_executions, root=0)

    if rank == 0:
        # 生成大矩阵 A 和 B
        A = np.random.rand(N, N)
        B = np.random.rand(N, N)
        
        # 将矩阵 A 分块
        chunks = np.array_split(A, size, axis=0)
    else:
        A = None
        B = None
        chunks = None

    # 将 A 的块分发给所有进程
    local_A = comm.scatter(chunks, root=0)

    # 将矩阵 B 广播给所有进程
    B = comm.bcast(B, root=0)

    # 记录每次执行的时间
    execution_times = []

    for _ in range(num_executions):
        # 记录开始时间
        start_time = time.time()

        # 执行局部矩阵乘法
        local_C = np.dot(local_A, B)

        # 将局部结果收集到最终矩阵 C 中
        C = comm.gather(local_C, root=0)

        # 记录结束时间
        end_time = time.time()

        if rank == 0:
            # 合并结果
            C = np.vstack(C)
            elapsed_time = end_time - start_time
            execution_times.append(elapsed_time)

    if rank == 0:
        # 输出每次执行的时间和平均时间
        for i, exec_time in enumerate(execution_times):
            print(f"第 {i+1} 次矩阵乘法耗时: {exec_time:.6f} 秒")
        avg_time = sum(execution_times) / num_executions
        print(f"平均耗时: {avg_time:.6f} 秒")

if __name__ == "__main__":
    main()
```
![13](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/13.png)

于是就又有了个优化方向——减少通信开销

## 四、各个库的优化情况

### mpi4y库的最终优化情况
（绝不是我懒得再优化了）
```python
from mpi4py import MPI
import time
import numpy as np

def main():
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()

    if rank == 0:
        # 输入矩阵大小和执行次数
        N = int(input("请输入矩阵大小："))
        num_executions = int(input("请输入执行次数："))
    else:
        N = None
        num_executions = None

    # 广播矩阵大小和执行次数给所有进程
    N = comm.bcast(N, root=0)
    num_executions = comm.bcast(num_executions, root=0)

    if rank == 0:
        # 生成大矩阵 A 和 B
        A = np.random.rand(N, N)
        B = np.random.rand(N, N)
        
        # 将矩阵 A 分块
        chunks = np.array_split(A, size, axis=0)
    else:
        A = None
        B = None
        chunks = None

    # 将 A 的块分发给所有进程
    local_A = comm.scatter(chunks, root=0)

    # 广播矩阵 B 给所有进程
    B = comm.bcast(B, root=0)

    # 记录每次执行的时间
    execution_times = []

    for _ in range(num_executions):
        # 记录开始时间
        start_time = time.time()

        # 执行局部矩阵乘法
        local_C = np.dot(local_A, B)

        # 将结果收集到主进程
        gathered_C = comm.gather(local_C, root=0)

        # 记录结束时间
        end_time = time.time()
        execution_times.append(end_time - start_time)

    if rank == 0:
        # 合并结果
        C = np.vstack(gathered_C)

        # 输出每次执行的时间和平均时间
        for i, exec_time in enumerate(execution_times):
            print(f"第 {i+1} 次矩阵乘法耗时: {exec_time:.6f} 秒")
        avg_time = sum(execution_times) / num_executions
        print(f"平均耗时: {avg_time:.6f} 秒")

        # 验证计算结果
        reference_C = np.dot(A, B)
        if np.allclose(C, reference_C):
            print("计算结果正确！")
        else:
            print("计算结果不正确！")

if __name__ == "__main__":
    main()
```
减少通信开销并优化分块方式后我们可以得到如上代码

同时加入psutil库来读取内存使用情况（即get_memory_usage函数）

保存实验数据至xlsx后

可将各个规模各个进程的耗时结果绘制成图（见第五部分）

（受限于虚拟机可用cpu数，进程数最多为4）

### 使用multiprocessing库进行优化
mpi4y是个实现多进程运算的第三方库

实际上Python标准库里的multiprocessing同样可以实现多进程计算

另外，joblib这个第三方库可以很好地使用multiprocessing来简化并行计算

所以我们可以直接调用joblib来使用multiprocessing而不用再调用multiprocessing

“在优化multiprocessing的过程中，我们把multiprocessing成功优化掉了”（大雾）

当然，就本质而言依旧是在使用multiprocessing来进行多进程运算

但比起直接使用multiprocessing来的话，用joblib来调用multiprocessing会更快一点

不过在实验过程中，也发现了joblib在更快的同时也占用了更多的内存

故最后加入几组直接使用multiprocessing的数据与之进行对比

以下为使用joblib进行矩阵计算的代码——
```python
import numpy as np
from joblib import Parallel, delayed
import time
import psutil
import os

#矩阵乘法函数
def 矩阵乘法(A, B):
    return np.dot(A, B)

#获取所有子进程的内存使用情况
def get_memory_usage(process):
    memory_usage = process.memory_info().rss  # 获取主进程的内存使用情况
    for child in process.children(recursive=True):
        memory_usage += child.memory_info().rss  # 累加所有子进程的内存使用情况
    return memory_usage / 1024 / 1024  # 转换为 MB

#验证计算结果是否正确
def 验证结果(C, reference_C):
    return np.allclose(C, reference_C)

#将矩阵分块
def 分块矩阵(A, B, num_blocks):
    n = A.shape[0]
    block_size = n // num_blocks
    A_blocks = [A[i*block_size:(i+1)*block_size, :] for i in range(num_blocks)]
    B_blocks = [B[i*block_size:(i+1)*block_size, :] for i in range(num_blocks)]
    return A_blocks, B_blocks

#主函数
def 主函数(matrix_size, num_experiments, num_processes):
    # 生成随机矩阵
    A = np.random.rand(matrix_size, matrix_size)
    B = np.random.rand(matrix_size, matrix_size)
    
    # 计算参考结果
    reference_C = np.dot(A, B)
    
    # 记录每次实验的耗时和内存使用情况
    耗时 = []
    内存使用 = []
    
    for _ in range(num_experiments):
        开始时间 = time.time()
        
        try:
            # 使用 joblib 并行计算矩阵乘法
            process = psutil.Process(os.getpid())
            
            # 将矩阵分块
            A_blocks, B_blocks = 分块矩阵(A, B, num_processes)
            
            # 并行计算每个块的乘积
            C_blocks = Parallel(n_jobs=num_processes)(delayed(矩阵乘法)(A_blocks[i], B) for i in range(num_processes))
            
            # 合并结果
            C = np.vstack(C_blocks)
            
            结束时间 = time.time()
            耗时.append(结束时间 - 开始时间)
            
            # 获取内存使用情况
            memory_usage = get_memory_usage(process)
        except Exception as e:
            print(f"计算过程中出现错误: {e}")
            C = None
            memory_usage = 0
            continue
        
        #记录内存使用情况
        内存使用.append(memory_usage)
    
    #打印每次实验的耗时和内存使用情况
    for i, (t, mem) in enumerate(zip(耗时, 内存使用)):
        print(f"实验 {i + 1}: {t:.6f} 秒, 内存使用: {mem:.2f} MB")
    
    #验证计算结果是否正确
    if C is not None and 验证结果(C, reference_C):
        print("计算结果正确。")
    else:
        print("计算结果错误。")

if __name__ == "__main__":
    #输入矩阵规模、实验次数和进程数
    矩阵规模 = int(input("请输入矩阵规模: "))
    实验次数 = int(input("请输入实验次数: "))
    进程数 = int(input("请输入进程数: "))
    
    主函数(矩阵规模, 实验次数, 进程数)
```
## 五、数据的可视化

### 绘制图像的程序
将数据记录在xlsx后复制给ai，它给我直接将数据转换成了字典+数组的形式

十分方便程序直接调用（喜）

以下为绘制有关耗时图像程序的代码部分——
```python
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

# 设置中文字体
font = FontProperties(fname='C:/Windows/Fonts/simsun.ttc')  # 你可以根据你的系统字体路径进行调整

# 创建数据字典
data_dict = {
    '优化情况': ['mpi4y'] * 7 + ['joblib'] * 7 + ['multiprocessing'] * 3,
    '项目规模': [10000, 10000, 10000, 8000, 4000, 2000, 1000, 1000, 2000, 4000, 8000, 10000, 10000, 10000, 10000, 10000, 10000],
    '进程数': [4, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 4, 2, 1],
    '平均耗时（秒）': [40.14404033, 45.58187767, 59.73926433, 15.12474867, 1.957008333, 0.281834, 0.082977, 0.378722667, 0.75945, 3.005522, 18.81784333, 38.36970167, 35.084648, 30.834548, 103.6220017, 69.22675867, 54.760433],
    '平均使用（MB）': [1889.383333, 2347.956667, 3120.396667, 1277.16, 379.6, 134.8133333, 71.87, 319.12, 479.9733333, 1058.383333, 2764.333333, 3898.37, 3834.633333, 3879.833333, 3459.333333, 3523.533333, 3708.586667]
}

# 将数据字典转换为 DataFrame
df = pd.DataFrame(data_dict)

# 过滤数据
df_mpi4py_4 = df[(df['优化情况'] == 'mpi4y') & (df['进程数'] == 4)]
df_mpi4py_10000 = df[(df['优化情况'] == 'mpi4y') & (df['项目规模'] == 10000)]
df_joblib_4 = df[(df['优化情况'] == 'joblib') & (df['进程数'] == 4)]
df_joblib_10000 = df[(df['优化情况'] == 'joblib') & (df['项目规模'] == 10000)]
df_multiprocessing_10000 = df[(df['优化情况'] == 'multiprocessing') & (df['项目规模'] == 10000)]
df_all_10000_4 = df[(df['项目规模'] == 10000) & (df['进程数'] == 4)]

# 绘制使用 mpi4y 且进程数都为 4 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_mpi4py_4['项目规模'].astype(str), df_mpi4py_4['平均耗时（秒）'], label='mpi4y')
plt.title('使用 mpi4y 且进程数都为 4 的平均耗时', fontproperties=font)
plt.xlabel('项目规模', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_mpi4py_4['平均耗时（秒）']) * 0.8, max(df_mpi4py_4['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 mpi4y 且数据规模皆为 10000 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_mpi4py_10000['进程数'].astype(str), df_mpi4py_10000['平均耗时（秒）'], label='mpi4y')
plt.title('使用 mpi4y 且数据规模皆为 10000 的平均耗时', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_mpi4py_10000['平均耗时（秒）']) * 0.8, max(df_mpi4py_10000['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 joblib 且进程数都为 4 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_joblib_4['项目规模'].astype(str), df_joblib_4['平均耗时（秒）'], label='joblib')
plt.title('使用 joblib 且进程数都为 4 的平均耗时', fontproperties=font)
plt.xlabel('项目规模', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_joblib_4['平均耗时（秒）']) * 0.8, max(df_joblib_4['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 joblib 且数据规模皆为 10000 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_joblib_10000['进程数'].astype(str), df_joblib_10000['平均耗时（秒）'], label='joblib')
plt.title('使用 joblib 且数据规模皆为 10000 的平均耗时', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_joblib_10000['平均耗时（秒）']) * 0.8, max(df_joblib_10000['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 multiprocessing 且数据规模皆为 10000 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_multiprocessing_10000['进程数'].astype(str), df_multiprocessing_10000['平均耗时（秒）'], label='multiprocessing')
plt.title('使用 multiprocessing 且数据规模皆为 10000 的平均耗时', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_multiprocessing_10000['平均耗时（秒）']) * 0.8, max(df_multiprocessing_10000['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制数据规模都为 10000 且进程数都为 4 的条形图
plt.figure(figsize=(12, 6))
plt.bar(df_all_10000_4['优化情况'], df_all_10000_4['平均耗时（秒）'], label='所有库')
plt.title('数据规模都为 10000 且进程数都为 4 的平均耗时', fontproperties=font)
plt.xlabel('优化情况', fontproperties=font)
plt.ylabel('平均耗时（秒）', fontproperties=font)
plt.ylim(min(df_all_10000_4['平均耗时（秒）']) * 0.8, max(df_all_10000_4['平均耗时（秒）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()
```
为了图像的区分度，部分图像纵坐标不从零开始

除此之外的数据（例如用手搓的矩阵算法）比较分析的价值不大，故未绘制图像

以下是有关内存占比的图像绘制，依葫芦画瓢即可
```python
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

# 设置中文字体
font = FontProperties(fname='C:/Windows/Fonts/simsun.ttc')  # 你可以根据你的系统字体路径进行调整

# 创建数据字典
data_dict = {
    '优化情况': ['mpi4y'] * 7 + ['joblib'] * 7 + ['multiprocessing'] * 3,
    '项目规模': [10000, 10000, 10000, 8000, 4000, 2000, 1000, 1000, 2000, 4000, 8000, 10000, 10000, 10000, 10000, 10000, 10000],
    '进程数': [4, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 1, 4, 2, 1],
    '平均耗时（秒）': [40.14404033, 45.58187767, 59.73926433, 15.12474867, 1.957008333, 0.281834, 0.082977, 0.378722667, 0.75945, 3.005522, 18.81784333, 38.36970167, 35.084648, 30.834548, 103.6220017, 69.22675867, 54.760433],
    '平均使用（MB）': [1889.383333, 2347.956667, 3120.396667, 1277.16, 379.6, 134.8133333, 71.87, 319.12, 479.9733333, 1058.383333, 2764.333333, 3898.37, 3834.633333, 3879.833333, 3459.333333, 3523.533333, 3708.586667]
}

# 将数据字典转换为 DataFrame
df = pd.DataFrame(data_dict)

# 过滤数据
df_mpi4py_4 = df[(df['优化情况'] == 'mpi4y') & (df['进程数'] == 4)]
df_mpi4py_10000 = df[(df['优化情况'] == 'mpi4y') & (df['项目规模'] == 10000)]
df_joblib_4 = df[(df['优化情况'] == 'joblib') & (df['进程数'] == 4)]
df_joblib_10000 = df[(df['优化情况'] == 'joblib') & (df['项目规模'] == 10000)]
df_multiprocessing_10000 = df[(df['优化情况'] == 'multiprocessing') & (df['项目规模'] == 10000)]
df_all_10000_4 = df[(df['项目规模'] == 10000) & (df['进程数'] == 4)]

# 绘制使用 mpi4y 且进程数都为 4 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_mpi4py_4['项目规模'].astype(str), df_mpi4py_4['平均使用（MB）'], label='mpi4y')
plt.title('使用 mpi4y 且进程数都为 4 的平均内存占用', fontproperties=font)
plt.xlabel('项目规模', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_mpi4py_4['平均使用（MB）']) * 0.8, max(df_mpi4py_4['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 mpi4y 且数据规模皆为 10000 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_mpi4py_10000['进程数'].astype(str), df_mpi4py_10000['平均使用（MB）'], label='mpi4y')
plt.title('使用 mpi4y 且数据规模皆为 10000 的平均内存占用', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_mpi4py_10000['平均使用（MB）']) * 0.8, max(df_mpi4py_10000['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 joblib 且进程数都为 4 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_joblib_4['项目规模'].astype(str), df_joblib_4['平均使用（MB）'], label='joblib')
plt.title('使用 joblib 且进程数都为 4 的平均内存占用', fontproperties=font)
plt.xlabel('项目规模', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_joblib_4['平均使用（MB）']) * 0.8, max(df_joblib_4['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 joblib 且数据规模皆为 10000 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_joblib_10000['进程数'].astype(str), df_joblib_10000['平均使用（MB）'], label='joblib')
plt.title('使用 joblib 且数据规模皆为 10000 的平均内存占用', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_joblib_10000['平均使用（MB）']) * 0.8, max(df_joblib_10000['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制使用 multiprocessing 且数据规模皆为 10000 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_multiprocessing_10000['进程数'].astype(str), df_multiprocessing_10000['平均使用（MB）'], label='multiprocessing')
plt.title('使用 multiprocessing 且数据规模皆为 10000 的平均内存占用', fontproperties=font)
plt.xlabel('进程数', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_multiprocessing_10000['平均使用（MB）']) * 0.8, max(df_multiprocessing_10000['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()

# 绘制数据规模都为 10000 且进程数都为 4 的条形图（内存占用）
plt.figure(figsize=(12, 6))
plt.bar(df_all_10000_4['优化情况'], df_all_10000_4['平均使用（MB）'], label='所有库')
plt.title('数据规模都为 10000 且进程数都为 4 的平均内存占用', fontproperties=font)
plt.xlabel('优化情况', fontproperties=font)
plt.ylabel('平均内存占用（MB）', fontproperties=font)
plt.ylim(min(df_all_10000_4['平均使用（MB）']) * 0.8, max(df_all_10000_4['平均使用（MB）']) * 1.2)  # 调整纵坐标范围
plt.legend(prop=font)
plt.grid(True)
plt.show()
```
### 图像结果
共12张图，（3张同规模同方法+2张同进程同方法+1张同规模同进程）*（耗时+内存）排列组合而得

#### 使用 mpi4y 且进程数都为 4 的平均耗时
![使用 mpi4y 且进程数都为 4 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/mpi4y_4.png)

#### 使用 mpi4y 且数据规模皆为 10000 的平均耗时
![使用 mpi4y 且数据规模皆为 10000 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/mpi4y_10000.png)

#### 使用 joblib 且进程数都为 4 的平均耗时
![使用 joblib 且进程数都为 4 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/joblib_4.png)

#### 使用 joblib 且数据规模皆为 10000 的平均耗时
![使用 joblib 且数据规模皆为 10000 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/joblib_10000.png)

#### 使用 multiprocessing 且数据规模皆为 10000 的平均耗时
![使用 multiprocessing 且数据规模皆为 10000 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/multi_10000.png)

#### 数据规模都为 10000 且进程数都为 4 的平均耗时
![数据规模都为 10000 且进程数都为 4 的平均耗时](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/10000_4.png)

#### 使用 mpi4y 且进程数都为 4 的平均内存占用
![使用 mpi4y 且进程数都为 4 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/mpi4y-4.png)

#### 使用 mpi4y 且数据规模皆为 10000 的平均内存占用
![使用 mpi4y 且数据规模皆为 10000 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/mpi4y-10000.png)

#### 使用 joblib 且进程数都为 4 的平均内存占用
![使用 joblib 且进程数都为 4 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/joblib-4.png)

#### 使用 joblib 且数据规模皆为 10000 的平均内存占用
![使用 joblib 且数据规模皆为 10000 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/joblib-10000.png)

#### 使用 multiprocessing 且数据规模皆为 10000 的平均内存占用
![使用 multiprocessing 且数据规模皆为 10000 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/multi-10000.png)

#### 数据规模都为 10000 且进程数都为 4 的平均内存占用
![数据规模都为 10000 且进程数都为 4 的平均内存占用](https://raw.githubusercontent.com/Sora-Niimi/2024NCUSCC-assessment/refs/heads/images1/10000-4.png)

## 六、实验过程中的问题与解决方案

### 添加库破坏当前python环境的问题
在虚拟机试图直接安装新的库时

偶尔会出现意为“如果这么干了你就要破坏你的python环境啦”这种报错

解决方案有三个——强行安装，直接使用pip来管理库，或者安装虚拟环境再下载库

强行安装自然不推荐，我在使用pip的时候也会有失败的时候

个人推荐还是安装一个虚拟环境，相较于前两者可能会复杂不少

但也不算很复杂，六个步骤（以下操作大多在终端完成）——

1、安装虚拟模块sudo apt-get install python3-venv

2、创建虚拟环境python3 -m venv venv

3、激活虚拟环境source venv/bin/activate

（我在创建虚拟环境后自动激活了，再次激活会进入虚拟环境的虚拟环境）

（此时可以通过deactivate退出一级虚拟环境）

4、使用pip安装库，操作同正常环境

5、（如果你是用vscode写代码）在vscode中更改python解释器，使用虚拟环境里的python解释器

（vscode中可用快捷键Ctrl+Shift+P打开命令面板）

（输入Python: Select Interpreter选择解释器，虚拟环境的路径通常是./venv/bin/python）

6、验证虚拟环境（以安装pandas为例），可跳过——

python -c "import pandas; print('Libraries installed successfully')"

### ai反复出错的调试方法（个人方案）
ai现如今对于一个初学者几乎是不可或缺的工具，写代码最难的从零到一可以通过ai来跳过

不用对着诸多的语法，一脸懵地不知从何着手

但或许是ai水平有限，或许是囊中羞涩买不起高级的ai

总之，在使用ai来代替人来敲代码的时候不可避免地出现ai“犯蠢”的现象

例如刚刚，我在用ai来编写可视化程序的时候

ai给我的字典的“优化情况”行中永远只有16项而不是17项，这导致数组长度不一致，运行时反复报错

将报错内容交给ai后它依然没有看出任何问题，重新写了代码后那一行还是16项

对于这类情况，最理想的是你自己有能力有时间来自己看出代码的毛病

但对于初学者来说这并不切实际，至少暂时是这样

所以我给出的调试方法是继续用ai，但必须换个角度

例如比较原始的方法——让ai将代码分块进行输出，逐步检验是哪里出了问题

或者是让ai“自我检讨”，让它自己先写明白每行代码的作用，然后人来看它写的“检讨书”哪里有问题

又或者直接换一家ai，让两家ai赛博斗蛐蛐（

总之一味让ai写代码目前并不可靠，除了人本身也需要学习与变通之外

在正确的提问基础之上，也不妨再去问问别人

## 琐碎的结语
以上，即本次实验报告全部内容

于10.26 22:30完成，接下来会将实验内容逐步上传至github

愿完成时仍是今天（

本人由于编程基础薄弱，却又大胆尝试同进行时rust基础试题与python考核

事实证明，多少是太大胆了些

一蹴而就的学习效果并不会好到哪去，拖延至DDL结束也不值得推荐

最后实验也只测试了两个半的库的耗时情况

在DDL逼近的时候，依然不紧不慢追求完成度，或许还勉强能称得上是个优点吧

至于CPU使用率的数据收集，在反复尝试下无果，只能暂时放弃

时间还是太少了，要学的东西还是太多了

总之感谢ncuscc的这次考核，让我有了个学习的方向与目标

但若不能通过的话就只好准备二周目了（悲）

唯一想参加的野鸡学生团体呀（其实可以把野鸡去掉）

### 特别鸣谢
彩彩([CAICAII](https://github.com/CAICAIIs)（八月底的时候被彩彩诱拐至此，才有了后来的故事）

牢E([teapot1de](https://github.com/ywh555hhh))（别的不说，牢e卖了我一辆99的二手自行车我可以记一辈子（欸嘿嘿））

回归天空([SXP-Simon](https://github.com/SXP-Simon))、太阳王子([THINKER](https://github.com/THINKER-ONLY/NCUSCC-Examination))(两个同样选python题的热心群友，前者还是第一个把我盒了的)

NCUSCC水群的米娜桑（最爱水的群）

[chatgpt4o](https://chatgpt.com/)（免费真的很香，copilot也是一个东西）
